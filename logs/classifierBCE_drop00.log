----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 140, 210]             896
              ReLU-2         [-1, 32, 140, 210]               0
       BatchNorm2d-3         [-1, 32, 140, 210]              64
            Conv2d-4         [-1, 32, 140, 210]           9,248
              ReLU-5         [-1, 32, 140, 210]               0
       BatchNorm2d-6         [-1, 32, 140, 210]              64
            Conv2d-7         [-1, 32, 140, 210]           9,248
              ReLU-8         [-1, 32, 140, 210]               0
       BatchNorm2d-9         [-1, 32, 140, 210]              64
           Conv2d-10         [-1, 32, 140, 210]           9,248
             ReLU-11         [-1, 32, 140, 210]               0
      BatchNorm2d-12         [-1, 32, 140, 210]              64
          Dropout-13         [-1, 32, 140, 210]               0
        AvgPool2d-14          [-1, 32, 70, 105]               0
           Conv2d-15          [-1, 64, 70, 105]          18,496
             ReLU-16          [-1, 64, 70, 105]               0
      BatchNorm2d-17          [-1, 64, 70, 105]             128
           Conv2d-18          [-1, 64, 70, 105]          36,928
             ReLU-19          [-1, 64, 70, 105]               0
      BatchNorm2d-20          [-1, 64, 70, 105]             128
           Conv2d-21          [-1, 64, 70, 105]          36,928
             ReLU-22          [-1, 64, 70, 105]               0
      BatchNorm2d-23          [-1, 64, 70, 105]             128
          Dropout-24          [-1, 64, 70, 105]               0
           Conv2d-25         [-1, 128, 70, 105]          73,856
             ReLU-26         [-1, 128, 70, 105]               0
      BatchNorm2d-27         [-1, 128, 70, 105]             256
           Conv2d-28         [-1, 128, 70, 105]         147,584
             ReLU-29         [-1, 128, 70, 105]               0
      BatchNorm2d-30         [-1, 128, 70, 105]             256
           Conv2d-31          [-1, 128, 36, 54]          16,512
             ReLU-32          [-1, 128, 36, 54]               0
      BatchNorm2d-33          [-1, 128, 36, 54]             256
        AvgPool2d-34            [-1, 128, 4, 6]               0
             View-35                 [-1, 3072]               0
           Linear-36                    [-1, 4]          12,292
          Sigmoid-37                    [-1, 4]               0
================================================================
Total params: 372,644
Trainable params: 372,644
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 179.80
Params size (MB): 1.42
Estimated Total Size (MB): 181.56
----------------------------------------------------------------
Reading data
Loaded data
----------
Test err: [0.5080429  0.42761394 0.47184987 0.3230563 ]
Test Loss: 0.6929077995846162
Epoch 1 loss = 1.0156111100403937
----------
Test err: [0.49061662 0.45040214 0.48525469 0.33243968]
Test Loss: 1.5151320103575892
Epoch 2 loss = 0.7459313858290461
----------
Test err: [0.44369973 0.4075067  0.47587131 0.36461126]
Test Loss: 0.6865692370778435
Epoch 3 loss = 0.6787279786756787
----------
Test err: [0.46380697 0.3538874  0.39276139 0.32573727]
Test Loss: 0.6557171820355804
Epoch 4 loss = 0.6587778750117919
----------
Test err: [0.4075067  0.37131367 0.44101877 0.31903485]
Test Loss: 0.6582985795315245
Epoch 5 loss = 0.633827282819927
----------
Test err: [0.47050938 0.35120643 0.5        0.35254692]
Test Loss: 0.6734414576445444
Epoch 6 loss = 0.6399700071153308
----------
Test err: [0.44369973 0.39142091 0.36863271 0.38605898]
Test Loss: 0.6640206293549998
Epoch 7 loss = 0.6341897035092515
----------
Test err: [0.43029491 0.3538874  0.38069705 0.31099196]
Test Loss: 0.6376919347902725
Epoch 8 loss = 0.6206573850347913
----------
Test err: [0.48659517 0.42359249 0.46648794 0.3230563 ]
Test Loss: 0.9015407333145512
Epoch 9 loss = 0.624619101551199
----------
Test err: [0.43297587 0.39008043 0.33646113 0.3150134 ]
Test Loss: 0.641514951058591
Epoch 10 loss = 0.6050799049576869
----------
Test err: [0.41152815 0.28016086 0.32037534 0.30697051]
Test Loss: 0.6051841923922061
Epoch 11 loss = 0.6087245142172233
----------
Test err: [0.36595174 0.26005362 0.31903485 0.3002681 ]
Test Loss: 0.5909821160597073
Epoch 12 loss = 0.6153974791953775
----------
Test err: [0.37801609 0.25067024 0.40214477 0.30563003]
Test Loss: 0.6158937505838379
Epoch 13 loss = 0.6024341480981249
----------
Test err: [0.3766756  0.3150134  0.37801609 0.35522788]
Test Loss: 0.6556880591242467
Epoch 14 loss = 0.6143413189269262
----------
Test err: [0.40348525 0.26273458 0.3310992  0.3150134 ]
Test Loss: 0.5905773140410157
Epoch 15 loss = 0.5999174178765223
----------
Test err: [0.41018767 0.26407507 0.36058981 0.27747989]
Test Loss: 0.6016536520709141
Epoch 16 loss = 0.5997135503362395
----------
Test err: [0.38873995 0.26005362 0.30831099 0.30831099]
Test Loss: 0.5928848656668421
Epoch 17 loss = 0.6015553384939404
----------
Test err: [0.35924933 0.24932976 0.32975871 0.31233244]
Test Loss: 0.5909930007786917
Epoch 18 loss = 0.594535192919161
----------
Test err: [0.44235925 0.26005362 0.3310992  0.29088472]
Test Loss: 0.5989356111265699
Epoch 19 loss = 0.6016125234777742
----------
Test err: [0.42895442 0.2613941  0.32841823 0.28016086]
Test Loss: 0.5988080578858667
Epoch 20 loss = 0.603354591626584
----------
Test err: [0.45710456 0.34450402 0.44504021 0.3150134 ]
Test Loss: 0.7431551938521958
Epoch 21 loss = 0.6014054777155613
----------
Test err: [0.37265416 0.37265416 0.31903485 0.33646113]
Test Loss: 0.6361996392262526
Epoch 22 loss = 0.6020571469621429
----------
Test err: [0.35924933 0.26809651 0.32439678 0.31635389]
Test Loss: 0.5921359373800876
Epoch 23 loss = 0.5996087265398163
----------
Test err: [0.41420912 0.24798928 0.30831099 0.30160858]
Test Loss: 0.5835237818053517
Epoch 24 loss = 0.5849373482826887
----------
Test err: [0.35924933 0.30428954 0.41823056 0.30294906]
Test Loss: 0.6352380745152846
Epoch 25 loss = 0.5831597260431693
----------
Test err: [0.40214477 0.25067024 0.3310992  0.3002681 ]
Test Loss: 0.5969555963320163
Epoch 26 loss = 0.5896257705407232
----------
Test err: [0.38203753 0.25469169 0.32707775 0.29490617]
Test Loss: 0.5846243360087315
Epoch 27 loss = 0.5880034644226606
----------
Test err: [0.39410188 0.269437   0.3538874  0.29490617]
Test Loss: 0.6242769136750227
Epoch 28 loss = 0.5900750888896052
----------
Test err: [0.38739946 0.25335121 0.32037534 0.34852547]
Test Loss: 0.5976850368861538
Epoch 29 loss = 0.5973261503687493
----------
Test err: [0.47184987 0.34048257 0.3150134  0.28686327]
Test Loss: 0.682977736480634
Epoch 30 loss = 0.5750975327581247
----------
Test err: [0.32975871 0.25201072 0.32707775 0.30428954]
Test Loss: 0.6263849272544998
Epoch 31 loss = 0.5866481903091513
----------
Test err: [0.43699732 0.22922252 0.30965147 0.28552279]
Test Loss: 0.6069556990433634
Epoch 32 loss = 0.5792648773091089
----------
Test err: [0.36461126 0.24128686 0.34048257 0.32573727]
Test Loss: 0.585523070063412
Epoch 33 loss = 0.5846327862854618
----------
Test err: [0.36193029 0.23994638 0.32707775 0.3002681 ]
Test Loss: 0.6041828198483259
Epoch 34 loss = 0.5821156720693246
----------
Test err: [0.36327078 0.29892761 0.35522788 0.30160858]
Test Loss: 0.628232562000646
Epoch 35 loss = 0.5807885444515831
----------
Test err: [0.43163539 0.23190349 0.34316354 0.33914209]
Test Loss: 0.6264515023668554
Epoch 36 loss = 0.5935252102706132
----------
Test err: [0.34852547 0.24932976 0.37399464 0.27882038]
Test Loss: 0.5912573554280935
Epoch 37 loss = 0.579828395440815
----------
Test err: [0.3766756  0.28150134 0.33646113 0.29356568]
Test Loss: 0.6043373645750192
Epoch 38 loss = 0.5829645994521337
----------
Test err: [0.40482574 0.24262735 0.31903485 0.29356568]
Test Loss: 0.5837485922585384
Epoch 39 loss = 0.5843047148101131
----------
Test err: [0.36058981 0.36327078 0.41420912 0.30294906]
Test Loss: 0.674894493233023
Epoch 40 loss = 0.5880097176370288
----------
Test err: [0.36327078 0.24530831 0.33512064 0.30160858]
Test Loss: 0.5837292664212452
Epoch 41 loss = 0.5739772893468432
----------
Test err: [0.3847185  0.25201072 0.36058981 0.29758713]
Test Loss: 0.5932063124674415
Epoch 42 loss = 0.5684983965219186
----------
Test err: [0.34182306 0.24798928 0.32707775 0.3002681 ]
Test Loss: 0.6460202677230333
Epoch 43 loss = 0.5708834345155364
----------
Test err: [0.4075067  0.28686327 0.34048257 0.3230563 ]
Test Loss: 0.6026002423832787
Epoch 44 loss = 0.5852579329033
----------
Test err: [0.37399464 0.28820375 0.3847185  0.30428954]
Test Loss: 0.6165795917385545
Epoch 45 loss = 0.5753347875285724
----------
Test err: [0.48659517 0.24932976 0.39812332 0.38605898]
Test Loss: 0.6905883583901874
Epoch 46 loss = 0.5787085804479052
----------
Test err: [0.40080429 0.3002681  0.38203753 0.30160858]
Test Loss: 0.770074606411179
Epoch 47 loss = 0.5704810457958293
----------
Test err: [0.34316354 0.24128686 0.33243968 0.27479893]
Test Loss: 0.5759264823728448
Epoch 48 loss = 0.5695319587998992
----------
Test err: [0.33646113 0.26005362 0.37935657 0.27345845]
Test Loss: 0.6048882971729973
Epoch 49 loss = 0.5638977480957399
----------
Test err: [0.37801609 0.25067024 0.32171582 0.40214477]
Test Loss: 0.6080569540108017
Epoch 50 loss = 0.5737688236198221
