----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 140, 210]             896
              ReLU-2         [-1, 32, 140, 210]               0
       BatchNorm2d-3         [-1, 32, 140, 210]              64
            Conv2d-4         [-1, 32, 140, 210]           9,248
              ReLU-5         [-1, 32, 140, 210]               0
       BatchNorm2d-6         [-1, 32, 140, 210]              64
            Conv2d-7         [-1, 32, 140, 210]           9,248
              ReLU-8         [-1, 32, 140, 210]               0
       BatchNorm2d-9         [-1, 32, 140, 210]              64
           Conv2d-10         [-1, 32, 140, 210]           9,248
             ReLU-11         [-1, 32, 140, 210]               0
      BatchNorm2d-12         [-1, 32, 140, 210]              64
          Dropout-13         [-1, 32, 140, 210]               0
        AvgPool2d-14          [-1, 32, 70, 105]               0
           Conv2d-15          [-1, 64, 70, 105]          18,496
             ReLU-16          [-1, 64, 70, 105]               0
      BatchNorm2d-17          [-1, 64, 70, 105]             128
           Conv2d-18          [-1, 64, 70, 105]          36,928
             ReLU-19          [-1, 64, 70, 105]               0
      BatchNorm2d-20          [-1, 64, 70, 105]             128
           Conv2d-21          [-1, 64, 70, 105]          36,928
             ReLU-22          [-1, 64, 70, 105]               0
      BatchNorm2d-23          [-1, 64, 70, 105]             128
          Dropout-24          [-1, 64, 70, 105]               0
           Conv2d-25         [-1, 128, 70, 105]          73,856
             ReLU-26         [-1, 128, 70, 105]               0
      BatchNorm2d-27         [-1, 128, 70, 105]             256
           Conv2d-28         [-1, 128, 70, 105]         147,584
             ReLU-29         [-1, 128, 70, 105]               0
      BatchNorm2d-30         [-1, 128, 70, 105]             256
           Conv2d-31          [-1, 128, 36, 54]          16,512
             ReLU-32          [-1, 128, 36, 54]               0
      BatchNorm2d-33          [-1, 128, 36, 54]             256
        AvgPool2d-34            [-1, 128, 4, 6]               0
             View-35                 [-1, 3072]               0
           Linear-36                    [-1, 4]          12,292
          Sigmoid-37                    [-1, 4]               0
================================================================
Total params: 372,644
Trainable params: 372,644
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 179.80
Params size (MB): 1.42
Estimated Total Size (MB): 181.56
----------------------------------------------------------------
Reading data
Loaded data
----------
Test err: [0.5080429  0.42761394 0.47184987 0.3230563 ]
Test Loss: 0.6929069848546394
Epoch 1 loss = 0.9754417652099445
----------
Test err: [0.47587131 0.41420912 0.42225201 0.39410188]
Test Loss: 0.7911884023760503
Epoch 2 loss = 0.7183981897364353
----------
Test err: [0.50134048 0.34048257 0.40884718 0.33780161]
Test Loss: 0.6645930029911267
Epoch 3 loss = 0.6684612237096792
----------
Test err: [0.47989276 0.33243968 0.42493298 0.30294906]
Test Loss: 0.6600786456913156
Epoch 4 loss = 0.6482537879381359
----------
Test err: [0.42091153 0.38739946 0.38739946 0.3150134 ]
Test Loss: 0.6530574154777917
Epoch 5 loss = 0.6297411918640137
----------
Test err: [0.43297587 0.30428954 0.41957105 0.31233244]
Test Loss: 0.649644718173362
Epoch 6 loss = 0.6228503139025404
----------
Test err: [0.45040214 0.32707775 0.41420912 0.31367292]
Test Loss: 0.6478125232573968
Epoch 7 loss = 0.626845631458804
----------
Test err: [0.42493298 0.29356568 0.33646113 0.30160858]
Test Loss: 0.6257695894858153
Epoch 8 loss = 0.6010688276457083
----------
Test err: [0.43431635 0.31635389 0.34852547 0.31099196]
Test Loss: 0.6378841573027919
Epoch 9 loss = 0.6214253197726232
----------
Test err: [0.43967828 0.30563003 0.36327078 0.32975871]
Test Loss: 0.6335861598798161
Epoch 10 loss = 0.6016327296121511
----------
Test err: [0.41152815 0.28150134 0.34986595 0.30697051]
Test Loss: 0.6169833894069968
Epoch 11 loss = 0.5997594331288785
----------
Test err: [0.43163539 0.39678284 0.45710456 0.30160858]
Test Loss: 0.8656610383904332
Epoch 12 loss = 0.6062890829733166
----------
Test err: [0.39276139 0.24530831 0.3230563  0.28552279]
Test Loss: 0.5936203337656509
Epoch 13 loss = 0.5915963084064924
----------
Test err: [0.41689008 0.29624665 0.38069705 0.31903485]
Test Loss: 0.6412746216202949
Epoch 14 loss = 0.6083175220374447
----------
Test err: [0.38739946 0.27479893 0.3150134  0.30160858]
Test Loss: 0.5959863500624656
Epoch 15 loss = 0.6153083160799246
----------
Test err: [0.40482574 0.26809651 0.3538874  0.30965147]
Test Loss: 0.6058955692833454
Epoch 16 loss = 0.6199011243380427
----------
Test err: [0.41152815 0.32975871 0.50670241 0.29624665]
Test Loss: 0.6653024239250865
Epoch 17 loss = 0.6209388287393401
----------
Test err: [0.41689008 0.3310992  0.34048257 0.29892761]
Test Loss: 0.6413983737315793
Epoch 18 loss = 0.6163741714513333
----------
Test err: [0.40482574 0.26809651 0.30428954 0.30563003]
Test Loss: 0.6003577529824771
Epoch 19 loss = 0.6084441537831488
----------
Test err: [0.42359249 0.34718499 0.39812332 0.30831099]
Test Loss: 0.6985803852531929
Epoch 20 loss = 0.5975913851254747
----------
Test err: [0.39946381 0.28686327 0.39142091 0.28954424]
Test Loss: 0.6190832033653522
Epoch 21 loss = 0.597125251395453
----------
Test err: [0.40214477 0.27345845 0.3002681  0.3150134 ]
Test Loss: 0.596798310211133
Epoch 22 loss = 0.6038737838773242
----------
Test err: [0.39946381 0.29892761 0.37265416 0.30563003]
Test Loss: 0.6380318431957718
Epoch 23 loss = 0.5982008419791112
----------
Test err: [0.40348525 0.27747989 0.34852547 0.30563003]
Test Loss: 0.6069376786356797
Epoch 24 loss = 0.5911093625881717
----------
Test err: [0.39276139 0.40616622 0.47453083 0.29624665]
Test Loss: 0.7023673992174561
Epoch 25 loss = 0.5986162099697635
----------
Test err: [0.41018767 0.26407507 0.36729223 0.37533512]
Test Loss: 0.6309360510522335
Epoch 26 loss = 0.590520067125479
----------
Test err: [0.39410188 0.28150134 0.35522788 0.32707775]
Test Loss: 0.6225191696120012
Epoch 27 loss = 0.5865251444300122
----------
Test err: [0.39142091 0.28016086 0.34986595 0.29624665]
Test Loss: 0.6009452817686921
Epoch 28 loss = 0.5892822318997524
----------
Test err: [0.39544236 0.25335121 0.31233244 0.2922252 ]
Test Loss: 0.5909020137091744
Epoch 29 loss = 0.5979756204755952
----------
Test err: [0.41286863 0.28418231 0.42627346 0.32037534]
Test Loss: 0.6420912513304652
Epoch 30 loss = 0.587355627291324
----------
Test err: [0.39410188 0.27345845 0.33914209 0.29356568]
Test Loss: 0.6091033229229837
Epoch 31 loss = 0.5894262525415292
----------
Test err: [0.38203753 0.31099196 0.44906166 0.29490617]
Test Loss: 0.6578598642726766
Epoch 32 loss = 0.5892379331844422
----------
Test err: [0.38739946 0.27882038 0.35120643 0.30563003]
Test Loss: 0.5976538940485138
Epoch 33 loss = 0.5939855094569618
----------
Test err: [0.39410188 0.26541555 0.36461126 0.29624665]
Test Loss: 0.6281082207342016
Epoch 34 loss = 0.5909052320204216
----------
Test err: [0.40482574 0.24932976 0.37935657 0.36193029]
Test Loss: 0.6281808855526408
Epoch 35 loss = 0.5943443668112358
----------
Test err: [0.43565684 0.27211796 0.3458445  0.28016086]
Test Loss: 0.6203257280324483
Epoch 36 loss = 0.5967097439011684
----------
Test err: [0.39142091 0.29088472 0.35120643 0.30697051]
Test Loss: 0.6325902297353776
Epoch 37 loss = 0.5908111902727838
----------
Test err: [0.40080429 0.24932976 0.33780161 0.27747989]
Test Loss: 0.5850675455556718
Epoch 38 loss = 0.5786968909064183
----------
Test err: [0.38873995 0.29356568 0.34450402 0.28284182]
Test Loss: 0.6225626486435972
Epoch 39 loss = 0.5753343661413116
----------
Test err: [0.35656836 0.25201072 0.34450402 0.27613941]
Test Loss: 0.6042721585667724
Epoch 40 loss = 0.59674817930917
----------
Test err: [0.39678284 0.23994638 0.38605898 0.28686327]
Test Loss: 0.6074464016321837
Epoch 41 loss = 0.5772152920191154
----------
Test err: [0.3538874  0.25871314 0.33243968 0.28820375]
Test Loss: 0.6020013922700613
Epoch 42 loss = 0.5766902515619754
----------
Test err: [0.37131367 0.26809651 0.35254692 0.29490617]
Test Loss: 0.595498468956583
Epoch 43 loss = 0.5790991372461294
----------
Test err: [0.3766756  0.230563   0.31635389 0.28820375]
Test Loss: 0.5775013550686533
Epoch 44 loss = 0.5702151739245765
----------
Test err: [0.36193029 0.24396783 0.30428954 0.28820375]
Test Loss: 0.6045900212461004
Epoch 45 loss = 0.5776938342217146
----------
Test err: [0.38605898 0.26273458 0.36058981 0.269437  ]
Test Loss: 0.6060042951740424
Epoch 46 loss = 0.5971069196114271
----------
Test err: [0.38605898 0.23190349 0.30965147 0.27211796]
Test Loss: 0.5706626956498415
Epoch 47 loss = 0.5833855145099016
----------
Test err: [0.3766756  0.25737265 0.3002681  0.26675603]
Test Loss: 0.5856075907006221
Epoch 48 loss = 0.5855068652303864
----------
Test err: [0.40884718 0.25469169 0.3538874  0.28150134]
Test Loss: 0.5959095222221303
Epoch 49 loss = 0.573544765765162
----------
Test err: [0.37801609 0.32037534 0.40348525 0.31099196]
Test Loss: 0.6969590902568188
Epoch 50 loss = 0.5735332491250843
