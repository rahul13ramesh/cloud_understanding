----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 140, 210]           1,792
       BatchNorm2d-2         [-1, 64, 140, 210]             128
              ReLU-3         [-1, 64, 140, 210]               0
            Conv2d-4         [-1, 64, 140, 210]          36,928
       BatchNorm2d-5         [-1, 64, 140, 210]             128
              ReLU-6         [-1, 64, 140, 210]               0
       double_conv-7         [-1, 64, 140, 210]               0
            inconv-8         [-1, 64, 140, 210]               0
         MaxPool2d-9          [-1, 64, 70, 105]               0
           Conv2d-10         [-1, 128, 70, 105]          73,856
      BatchNorm2d-11         [-1, 128, 70, 105]             256
             ReLU-12         [-1, 128, 70, 105]               0
           Conv2d-13         [-1, 128, 70, 105]         147,584
      BatchNorm2d-14         [-1, 128, 70, 105]             256
             ReLU-15         [-1, 128, 70, 105]               0
      double_conv-16         [-1, 128, 70, 105]               0
             down-17         [-1, 128, 70, 105]               0
        MaxPool2d-18          [-1, 128, 35, 52]               0
           Conv2d-19          [-1, 256, 35, 52]         295,168
      BatchNorm2d-20          [-1, 256, 35, 52]             512
             ReLU-21          [-1, 256, 35, 52]               0
           Conv2d-22          [-1, 256, 35, 52]         590,080
      BatchNorm2d-23          [-1, 256, 35, 52]             512
             ReLU-24          [-1, 256, 35, 52]               0
      double_conv-25          [-1, 256, 35, 52]               0
             down-26          [-1, 256, 35, 52]               0
        MaxPool2d-27          [-1, 256, 17, 26]               0
           Conv2d-28          [-1, 512, 17, 26]       1,180,160
      BatchNorm2d-29          [-1, 512, 17, 26]           1,024
             ReLU-30          [-1, 512, 17, 26]               0
           Conv2d-31          [-1, 512, 17, 26]       2,359,808
      BatchNorm2d-32          [-1, 512, 17, 26]           1,024
             ReLU-33          [-1, 512, 17, 26]               0
      double_conv-34          [-1, 512, 17, 26]               0
             down-35          [-1, 512, 17, 26]               0
        MaxPool2d-36           [-1, 512, 8, 13]               0
           Conv2d-37           [-1, 512, 8, 13]       2,359,808
      BatchNorm2d-38           [-1, 512, 8, 13]           1,024
             ReLU-39           [-1, 512, 8, 13]               0
           Conv2d-40           [-1, 512, 8, 13]       2,359,808
      BatchNorm2d-41           [-1, 512, 8, 13]           1,024
             ReLU-42           [-1, 512, 8, 13]               0
      double_conv-43           [-1, 512, 8, 13]               0
             down-44           [-1, 512, 8, 13]               0
  ConvTranspose2d-45          [-1, 512, 16, 26]       1,049,088
           Conv2d-46          [-1, 256, 17, 26]       2,359,552
      BatchNorm2d-47          [-1, 256, 17, 26]             512
             ReLU-48          [-1, 256, 17, 26]               0
           Conv2d-49          [-1, 256, 17, 26]         590,080
      BatchNorm2d-50          [-1, 256, 17, 26]             512
             ReLU-51          [-1, 256, 17, 26]               0
      double_conv-52          [-1, 256, 17, 26]               0
               up-53          [-1, 256, 17, 26]               0
  ConvTranspose2d-54          [-1, 256, 34, 52]         262,400
           Conv2d-55          [-1, 128, 35, 52]         589,952
      BatchNorm2d-56          [-1, 128, 35, 52]             256
             ReLU-57          [-1, 128, 35, 52]               0
           Conv2d-58          [-1, 128, 35, 52]         147,584
      BatchNorm2d-59          [-1, 128, 35, 52]             256
             ReLU-60          [-1, 128, 35, 52]               0
      double_conv-61          [-1, 128, 35, 52]               0
               up-62          [-1, 128, 35, 52]               0
  ConvTranspose2d-63         [-1, 128, 70, 104]          65,664
           Conv2d-64          [-1, 64, 70, 105]         147,520
      BatchNorm2d-65          [-1, 64, 70, 105]             128
             ReLU-66          [-1, 64, 70, 105]               0
           Conv2d-67          [-1, 64, 70, 105]          36,928
      BatchNorm2d-68          [-1, 64, 70, 105]             128
             ReLU-69          [-1, 64, 70, 105]               0
      double_conv-70          [-1, 64, 70, 105]               0
               up-71          [-1, 64, 70, 105]               0
  ConvTranspose2d-72         [-1, 64, 140, 210]          16,448
           Conv2d-73         [-1, 64, 140, 210]          73,792
      BatchNorm2d-74         [-1, 64, 140, 210]             128
             ReLU-75         [-1, 64, 140, 210]               0
           Conv2d-76         [-1, 64, 140, 210]          36,928
      BatchNorm2d-77         [-1, 64, 140, 210]             128
             ReLU-78         [-1, 64, 140, 210]               0
      double_conv-79         [-1, 64, 140, 210]               0
               up-80         [-1, 64, 140, 210]               0
           Conv2d-81          [-1, 4, 140, 210]             260
          outconv-82          [-1, 4, 140, 210]               0
================================================================
Total params: 14,789,124
Trainable params: 14,789,124
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 417.42
Params size (MB): 56.42
Estimated Total Size (MB): 474.17
----------------------------------------------------------------
Learning rate: 0.0004
Augmentation: 0
2019-12-13 00:11:45.988825
Using Lovasz
Reading data
Loaded data
Training model
Dice: 0.22781732715787018
Loss: 1.0562244401220982
Epoch 1 loss = 1.0076587225000064
-------------
Dice: 0.2758138782299733
Loss: 1.002636341882455
Epoch 2 loss = 1.0019585957129797
-------------
Dice: 0.27266393561063273
Loss: 1.0015945172501632
Epoch 3 loss = 1.0010454220573108
-------------
Dice: 0.30063241107036104
Loss: 1.0008885274783537
Epoch 4 loss = 1.000629071990649
-------------
Dice: 0.2887811418782289
Loss: 1.0006085335409354
Epoch 5 loss = 1.0005011629064877
-------------
Dice: 0.2697842955297661
Loss: 1.000586715524382
Epoch 6 loss = 1.0002634799977144
-------------
Dice: 0.24742459598377348
Loss: 1.0001768130239788
Epoch 7 loss = 1.0002176532149314
-------------
Dice: 0.35299310497612457
Loss: 1.0001827220335084
Epoch 8 loss = 1.0002229843537014
-------------
Dice: 0.18496333916270974
Loss: 1.0003594987034479
Epoch 9 loss = 1.000397496720155
-------------
Dice: 0.28355403088002573
Loss: 1.0001107062794887
Epoch 10 loss = 1.000330123603344
-------------
Dice: 0.2667945000662347
Loss: 1.000243321101084
Epoch 11 loss = 1.000299036204815
-------------
Dice: 0.24839072823942474
Loss: 1.0003681317890618
Epoch 12 loss = 1.0002370695273082
-------------
Dice: 0.27744800409695125
Loss: 1.0001088288929763
Epoch 13 loss = 1.0001853312055269
-------------
Dice: 0.2939620658424789
Loss: 1.0003515926986213
Epoch 14 loss = 1.0002784556150437
-------------
Dice: 0.18394901046155493
Loss: 1.0003071124528113
Epoch 15 loss = 1.0001981543501217
-------------
Dice: 0.2590659741561325
Loss: 1.0002407600189342
Epoch 16 loss = 1.0001968336105347
-------------
Dice: 0.40036546281363566
Loss: 1.0000730107361127
Epoch 17 loss = 1.0001939258972803
-------------
Dice: 0.27253853946257145
Loss: 1.0002313297012217
Epoch 18 loss = 1.0002059067289035
-------------
Dice: 0.3954271016581163
Loss: 1.0000987339754845
Epoch 19 loss = 1.0001864591240883
-------------
Dice: 0.31483452783723104
Loss: 1.0002468494403778
Epoch 20 loss = 1.000181965380907
-------------
Dice: 0.3591853896879977
Loss: 1.0001572278645339
Epoch 21 loss = 1.000189470946789
-------------
Dice: 0.34147240981746957
Loss: 1.0001558500863912
Epoch 22 loss = 1.0001647322873275
-------------
Dice: 0.41037186463208575
Loss: 1.0000747745861636
Epoch 23 loss = 1.000180098861456
-------------
Dice: 0.32501326109112116
Loss: 1.0001619907230859
Epoch 24 loss = 1.0001947844525179
-------------
Dice: 0.272211990678899
Loss: 1.0002975480645975
Epoch 25 loss = 1.0001661787430445
-------------
Dice: 0.4107041163754537
Loss: 1.0001455910563788
Epoch 26 loss = 1.0001747897267341
-------------
Dice: 0.3483746186367014
Loss: 1.0001780989981848
