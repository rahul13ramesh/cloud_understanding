----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 140, 210]           1,792
              ReLU-2         [-1, 64, 140, 210]               0
       BatchNorm2d-3         [-1, 64, 140, 210]             128
            Conv2d-4         [-1, 64, 140, 210]          36,928
              ReLU-5         [-1, 64, 140, 210]               0
       BatchNorm2d-6         [-1, 64, 140, 210]             128
            Conv2d-7         [-1, 64, 140, 210]          36,928
              ReLU-8         [-1, 64, 140, 210]               0
       BatchNorm2d-9         [-1, 64, 140, 210]             128
           Conv2d-10         [-1, 64, 140, 210]          36,928
             ReLU-11         [-1, 64, 140, 210]               0
      BatchNorm2d-12         [-1, 64, 140, 210]             128
          Dropout-13         [-1, 64, 140, 210]               0
        AvgPool2d-14          [-1, 64, 70, 105]               0
           Conv2d-15         [-1, 128, 70, 105]          73,856
             ReLU-16         [-1, 128, 70, 105]               0
      BatchNorm2d-17         [-1, 128, 70, 105]             256
           Conv2d-18         [-1, 128, 70, 105]         147,584
             ReLU-19         [-1, 128, 70, 105]               0
      BatchNorm2d-20         [-1, 128, 70, 105]             256
           Conv2d-21         [-1, 128, 70, 105]         147,584
             ReLU-22         [-1, 128, 70, 105]               0
      BatchNorm2d-23         [-1, 128, 70, 105]             256
          Dropout-24         [-1, 128, 70, 105]               0
           Conv2d-25         [-1, 256, 70, 105]         295,168
             ReLU-26         [-1, 256, 70, 105]               0
      BatchNorm2d-27         [-1, 256, 70, 105]             512
           Conv2d-28         [-1, 256, 70, 105]         590,080
             ReLU-29         [-1, 256, 70, 105]               0
      BatchNorm2d-30         [-1, 256, 70, 105]             512
           Conv2d-31          [-1, 256, 36, 54]          65,792
             ReLU-32          [-1, 256, 36, 54]               0
      BatchNorm2d-33          [-1, 256, 36, 54]             512
        AvgPool2d-34            [-1, 256, 4, 6]               0
             View-35                 [-1, 6144]               0
           Linear-36                    [-1, 4]          24,580
          Sigmoid-37                    [-1, 4]               0
================================================================
Total params: 1,460,036
Trainable params: 1,460,036
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 359.60
Params size (MB): 5.57
Estimated Total Size (MB): 365.51
----------------------------------------------------------------
Reading data
Loaded data
----------
Test err: [0.4919571  0.57238606 0.52815013 0.6769437 ]
Test Loss: 0.6937151639934519
Epoch 1 loss = 0.7133793818087744
----------
Test err: [0.50536193 0.36729223 0.45576408 0.31769437]
Test Loss: 0.7819208768283793
Epoch 2 loss = 0.6587071500259174
----------
Test err: [0.43699732 0.3230563  0.42895442 0.32171582]
Test Loss: 0.6618472562738302
Epoch 3 loss = 0.6560647610684822
----------
Test err: [0.45710456 0.28954424 0.36058981 0.33243968]
Test Loss: 0.6361220991363794
Epoch 4 loss = 0.6327649300603381
----------
Test err: [0.44101877 0.39544236 0.39276139 0.3230563 ]
Test Loss: 0.7221608289465029
Epoch 5 loss = 0.6309459461922939
----------
Test err: [0.43163539 0.28552279 0.38873995 0.32037534]
Test Loss: 0.6335618827322214
Epoch 6 loss = 0.6191795770348557
----------
Test err: [0.4155496  0.26541555 0.3538874  0.3150134 ]
Test Loss: 0.6607221581538685
Epoch 7 loss = 0.6195606122707235
----------
Test err: [0.44906166 0.24932976 0.3458445  0.32171582]
Test Loss: 0.6400963512446541
Epoch 8 loss = 0.5961411660861713
----------
Test err: [0.39946381 0.3150134  0.37399464 0.32439678]
Test Loss: 0.6513040364287973
Epoch 9 loss = 0.6046750740455239
----------
Test err: [0.39008043 0.28418231 0.32037534 0.31635389]
Test Loss: 0.6027567316990236
Epoch 10 loss = 0.6003780898715472
----------
Test err: [0.41152815 0.25469169 0.33243968 0.29088472]
Test Loss: 0.5948890703642896
Epoch 11 loss = 0.5900642879846588
----------
Test err: [0.38605898 0.31903485 0.35254692 0.32171582]
Test Loss: 0.6301442132888228
Epoch 12 loss = 0.6018359053869989
----------
Test err: [0.38873995 0.27613941 0.36193029 0.3458445 ]
Test Loss: 0.6309511696635158
Epoch 13 loss = 0.5877804200067597
----------
Test err: [0.36595174 0.25469169 0.31099196 0.28150134]
Test Loss: 0.584001797972991
Epoch 14 loss = 0.5914253920077
----------
Test err: [0.39008043 0.26809651 0.3310992  0.27211796]
Test Loss: 0.5902283137049975
Epoch 15 loss = 0.5994147637574346
----------
Test err: [0.38337802 0.36327078 0.36058981 0.26273458]
Test Loss: 0.6544393550095225
Epoch 16 loss = 0.5876209042347149
----------
Test err: [0.41152815 0.29490617 0.33914209 0.28418231]
Test Loss: 0.6145947367232543
Epoch 17 loss = 0.5719767743397015
----------
Test err: [0.37399464 0.24396783 0.32439678 0.27882038]
Test Loss: 0.5856360064085383
Epoch 18 loss = 0.5862725722246451
----------
Test err: [0.41286863 0.25067024 0.32975871 0.29624665]
Test Loss: 0.5947170439538304
Epoch 19 loss = 0.5857151665252911
----------
Test err: [0.36327078 0.24530831 0.31099196 0.27345845]
Test Loss: 0.5836951405099585
Epoch 20 loss = 0.5840223118383188
----------
Test err: [0.38203753 0.25871314 0.33512064 0.29490617]
Test Loss: 0.6038871410604936
Epoch 21 loss = 0.576589429026954
----------
Test err: [0.39008043 0.24798928 0.32573727 0.27479893]
Test Loss: 0.5907782897972389
Epoch 22 loss = 0.5830778962165997
----------
Test err: [0.34852547 0.27345845 0.32841823 0.29490617]
Test Loss: 0.5871068594363036
Epoch 23 loss = 0.5925854374192675
----------
Test err: [0.40214477 0.29758713 0.35120643 0.27882038]
Test Loss: 0.6290672376187613
Epoch 24 loss = 0.5845784664793244
----------
Test err: [0.35254692 0.23726542 0.34986595 0.28686327]
Test Loss: 0.5819541787873485
Epoch 25 loss = 0.5681991957467618
----------
Test err: [0.34182306 0.25067024 0.33646113 0.26407507]
Test Loss: 0.5831222032314172
Epoch 26 loss = 0.5664093507998111
----------
Test err: [0.36595174 0.25469169 0.31903485 0.30294906]
Test Loss: 0.5847223139400457
Epoch 27 loss = 0.5709353237944698
----------
Test err: [0.3766756  0.26273458 0.35254692 0.34718499]
Test Loss: 0.6177637371716487
Epoch 28 loss = 0.5680698420023471
----------
Test err: [0.36058981 0.26005362 0.33378016 0.29356568]
Test Loss: 0.5856099208622132
Epoch 29 loss = 0.556844329706146
----------
Test err: [0.35656836 0.26005362 0.30563003 0.28016086]
Test Loss: 0.5855593392250925
Epoch 30 loss = 0.5622965629554626
----------
Test err: [0.3766756  0.25603217 0.31099196 0.3002681 ]
Test Loss: 0.5826276776008807
Epoch 31 loss = 0.5528588314158667
----------
Test err: [0.36193029 0.24530831 0.32707775 0.29758713]
Test Loss: 0.5958926858725001
Epoch 32 loss = 0.5710664947614593
----------
Test err: [0.36997319 0.26675603 0.33780161 0.3150134 ]
Test Loss: 0.59526289547057
Epoch 33 loss = 0.5623998141800111
----------
Test err: [0.34986595 0.24664879 0.3230563  0.30428954]
Test Loss: 0.5878885178439739
Epoch 34 loss = 0.5625056820964046
----------
Test err: [0.37533512 0.24798928 0.32439678 0.29624665]
Test Loss: 0.5879369457938955
Epoch 35 loss = 0.5621640282725521
----------
Test err: [0.4075067  0.25871314 0.31367292 0.32573727]
Test Loss: 0.6004878118654199
Epoch 36 loss = 0.5705729110950439
----------
Test err: [0.39276139 0.25737265 0.31099196 0.28954424]
Test Loss: 0.5870793627290399
Epoch 37 loss = 0.5436195042433751
----------
Test err: [0.36595174 0.24128686 0.31233244 0.25335121]
Test Loss: 0.5956965478152116
Epoch 38 loss = 0.547500388072579
----------
Test err: [0.36729223 0.24530831 0.33243968 0.28016086]
Test Loss: 0.5907265036429301
Epoch 39 loss = 0.5439439713155936
----------
Test err: [0.34316354 0.26675603 0.3230563  0.29758713]
Test Loss: 0.6029868034531061
Epoch 40 loss = 0.5474782141859346
----------
Test err: [0.36193029 0.24262735 0.32573727 0.28552279]
Test Loss: 0.5702725378371994
Epoch 41 loss = 0.5554005251173679
----------
Test err: [0.36595174 0.25067024 0.30428954 0.30831099]
Test Loss: 0.5853381482110266
Epoch 42 loss = 0.5518665169902526
----------
Test err: [0.34986595 0.24664879 0.30831099 0.28284182]
Test Loss: 0.5753236483462933
Epoch 43 loss = 0.5546018816830326
----------
Test err: [0.35924933 0.23994638 0.30428954 0.28150134]
Test Loss: 0.5801849043441202
Epoch 44 loss = 0.544532855618096
----------
Test err: [0.32707775 0.24396783 0.2922252  0.27747989]
Test Loss: 0.5744159222498096
Epoch 45 loss = 0.5294978799193538
----------
Test err: [0.36193029 0.23994638 0.31769437 0.30160858]
Test Loss: 0.5774596366262308
Epoch 46 loss = 0.5297495877774727
----------
Test err: [0.33512064 0.23458445 0.32841823 0.27077748]
Test Loss: 0.5781477522654284
Epoch 47 loss = 0.5329115202215977
----------
Test err: [0.36997319 0.25737265 0.31769437 0.30294906]
Test Loss: 0.590628374023388
Epoch 48 loss = 0.54246586561203
----------
Test err: [0.34450402 0.24932976 0.31635389 0.3002681 ]
Test Loss: 0.5819453207011916
Epoch 49 loss = 0.5331679795926122
----------
Test err: [0.35254692 0.24128686 0.30563003 0.29624665]
Test Loss: 0.5849266889138053
Epoch 50 loss = 0.5236761902356595
