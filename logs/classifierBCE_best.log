----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 140, 210]           1,792
              ReLU-2         [-1, 64, 140, 210]               0
       BatchNorm2d-3         [-1, 64, 140, 210]             128
            Conv2d-4         [-1, 64, 140, 210]          36,928
              ReLU-5         [-1, 64, 140, 210]               0
       BatchNorm2d-6         [-1, 64, 140, 210]             128
            Conv2d-7         [-1, 64, 140, 210]          36,928
              ReLU-8         [-1, 64, 140, 210]               0
       BatchNorm2d-9         [-1, 64, 140, 210]             128
           Conv2d-10         [-1, 64, 140, 210]          36,928
             ReLU-11         [-1, 64, 140, 210]               0
      BatchNorm2d-12         [-1, 64, 140, 210]             128
          Dropout-13         [-1, 64, 140, 210]               0
        AvgPool2d-14          [-1, 64, 70, 105]               0
           Conv2d-15         [-1, 128, 70, 105]          73,856
             ReLU-16         [-1, 128, 70, 105]               0
      BatchNorm2d-17         [-1, 128, 70, 105]             256
           Conv2d-18         [-1, 128, 70, 105]         147,584
             ReLU-19         [-1, 128, 70, 105]               0
      BatchNorm2d-20         [-1, 128, 70, 105]             256
           Conv2d-21         [-1, 128, 70, 105]         147,584
             ReLU-22         [-1, 128, 70, 105]               0
      BatchNorm2d-23         [-1, 128, 70, 105]             256
          Dropout-24         [-1, 128, 70, 105]               0
           Conv2d-25         [-1, 256, 70, 105]         295,168
             ReLU-26         [-1, 256, 70, 105]               0
      BatchNorm2d-27         [-1, 256, 70, 105]             512
           Conv2d-28         [-1, 256, 70, 105]         590,080
             ReLU-29         [-1, 256, 70, 105]               0
      BatchNorm2d-30         [-1, 256, 70, 105]             512
           Conv2d-31          [-1, 256, 36, 54]          65,792
             ReLU-32          [-1, 256, 36, 54]               0
      BatchNorm2d-33          [-1, 256, 36, 54]             512
        AvgPool2d-34            [-1, 256, 4, 6]               0
             View-35                 [-1, 6144]               0
           Linear-36                    [-1, 4]          24,580
          Sigmoid-37                    [-1, 4]               0
================================================================
Total params: 1,460,036
Trainable params: 1,460,036
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 359.60
Params size (MB): 5.57
Estimated Total Size (MB): 365.51
----------------------------------------------------------------
2019-12-13 12:11:17.814197
Reading data
Loaded data
----------
Test err: [0.4919571  0.57238606 0.52815013 0.6769437 ]
Test Loss: 0.6937151639934519
Epoch 1 loss = 0.6600945054243008
----------
Test err: [0.46246649 0.27747989 0.34316354 0.3002681 ]
Test Loss: 0.6188752130472948
Epoch 2 loss = 0.6140109028915565
----------
Test err: [0.39946381 0.34316354 0.33780161 0.32841823]
Test Loss: 0.642139596819638
Epoch 3 loss = 0.6038448878626028
----------
Test err: [0.39142091 0.23994638 0.31903485 0.30831099]
Test Loss: 0.5855810684888516
Epoch 4 loss = 0.5961709905664127
----------
Test err: [0.33512064 0.27345845 0.34718499 0.28016086]
Test Loss: 0.6044550667074946
Epoch 5 loss = 0.5885838281363249
----------
Test err: [0.38337802 0.24530831 0.31769437 0.28820375]
Test Loss: 0.5866963155817331
Epoch 6 loss = 0.5801431619624297
----------
Test err: [0.40214477 0.25067024 0.3150134  0.30965147]
Test Loss: 0.5836417778637311
Epoch 7 loss = 0.5682888880123694
----------
Test err: [0.37533512 0.24932976 0.35924933 0.28284182]
Test Loss: 0.600216211965832
Epoch 8 loss = 0.5663203945507606
----------
Test err: [0.36193029 0.24530831 0.30831099 0.28954424]
Test Loss: 0.5663554251853167
Epoch 9 loss = 0.5545214832574129
----------
Test err: [0.41420912 0.230563   0.34852547 0.27747989]
Test Loss: 0.5877014526550536
Epoch 10 loss = 0.5532349784920613
----------
Test err: [0.34182306 0.23458445 0.3150134  0.2922252 ]
Test Loss: 0.5717887394729473
Epoch 11 loss = 0.5420975554734468
----------
Test err: [0.35254692 0.25737265 0.30697051 0.2922252 ]
Test Loss: 0.5788687993410285
Epoch 12 loss = 0.5374201419825355
----------
Test err: [0.36863271 0.21715818 0.31099196 0.3002681 ]
Test Loss: 0.5680240422147689
