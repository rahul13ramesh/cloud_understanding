----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 140, 210]           1,792
              ReLU-2         [-1, 64, 140, 210]               0
       BatchNorm2d-3         [-1, 64, 140, 210]             128
            Conv2d-4         [-1, 64, 140, 210]          36,928
              ReLU-5         [-1, 64, 140, 210]               0
       BatchNorm2d-6         [-1, 64, 140, 210]             128
            Conv2d-7         [-1, 64, 140, 210]          36,928
              ReLU-8         [-1, 64, 140, 210]               0
       BatchNorm2d-9         [-1, 64, 140, 210]             128
           Conv2d-10         [-1, 64, 140, 210]          36,928
             ReLU-11         [-1, 64, 140, 210]               0
      BatchNorm2d-12         [-1, 64, 140, 210]             128
          Dropout-13         [-1, 64, 140, 210]               0
        AvgPool2d-14          [-1, 64, 70, 105]               0
           Conv2d-15         [-1, 128, 70, 105]          73,856
             ReLU-16         [-1, 128, 70, 105]               0
      BatchNorm2d-17         [-1, 128, 70, 105]             256
           Conv2d-18         [-1, 128, 70, 105]         147,584
             ReLU-19         [-1, 128, 70, 105]               0
      BatchNorm2d-20         [-1, 128, 70, 105]             256
           Conv2d-21         [-1, 128, 70, 105]         147,584
             ReLU-22         [-1, 128, 70, 105]               0
      BatchNorm2d-23         [-1, 128, 70, 105]             256
          Dropout-24         [-1, 128, 70, 105]               0
           Conv2d-25         [-1, 256, 70, 105]         295,168
             ReLU-26         [-1, 256, 70, 105]               0
      BatchNorm2d-27         [-1, 256, 70, 105]             512
           Conv2d-28         [-1, 256, 70, 105]         590,080
             ReLU-29         [-1, 256, 70, 105]               0
      BatchNorm2d-30         [-1, 256, 70, 105]             512
           Conv2d-31          [-1, 256, 36, 54]          65,792
             ReLU-32          [-1, 256, 36, 54]               0
      BatchNorm2d-33          [-1, 256, 36, 54]             512
        AvgPool2d-34            [-1, 256, 4, 6]               0
             View-35                 [-1, 6144]               0
           Linear-36                    [-1, 4]          24,580
          Sigmoid-37                    [-1, 4]               0
================================================================
Total params: 1,460,036
Trainable params: 1,460,036
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.34
Forward/backward pass size (MB): 359.60
Params size (MB): 5.57
Estimated Total Size (MB): 365.51
----------------------------------------------------------------
Reading data
Loaded data
----------
Test err: [0.4919571  0.57238606 0.52815013 0.6769437 ]
Test Loss: 0.6937151639934519
Epoch 1 loss = 1.3118621579124206
----------
Test err: [0.52546917 0.39008043 0.45442359 0.38337802]
Test Loss: 1.0411403793392169
Epoch 2 loss = 0.7969343366635708
----------
Test err: [0.43297587 0.41152815 0.46782842 0.31769437]
Test Loss: 0.7030490386042614
Epoch 3 loss = 0.6951666870641325
----------
Test err: [0.47855228 0.34182306 0.40482574 0.31635389]
Test Loss: 0.7119827776068657
Epoch 4 loss = 0.6742803994516265
----------
Test err: [0.45174263 0.34986595 0.38605898 0.32171582]
Test Loss: 0.7421386827872042
Epoch 5 loss = 0.6490065119860958
----------
Test err: [0.42091153 0.36997319 0.42895442 0.31769437]
Test Loss: 0.6757473474013901
Epoch 6 loss = 0.6305267946649812
----------
Test err: [0.43029491 0.30428954 0.39678284 0.30160858]
Test Loss: 0.6509666267992185
Epoch 7 loss = 0.6173814223534939
----------
Test err: [0.42895442 0.32573727 0.36058981 0.34048257]
Test Loss: 0.6433790946534108
Epoch 8 loss = 0.619996409633524
----------
Test err: [0.4463807  0.28418231 0.37131367 0.30160858]
Test Loss: 0.629252539882711
Epoch 9 loss = 0.6213636035574026
----------
Test err: [0.44369973 0.27345845 0.44369973 0.31099196]
Test Loss: 0.642258801624858
Epoch 10 loss = 0.6213363193315091
----------
Test err: [0.43967828 0.4075067  0.47184987 0.4155496 ]
Test Loss: 0.7081118064455628
Epoch 11 loss = 0.6132125961556831
----------
Test err: [0.45442359 0.27613941 0.35522788 0.29088472]
Test Loss: 0.6279615323900697
Epoch 12 loss = 0.6101415780530218
----------
Test err: [0.45308311 0.27479893 0.3766756  0.36327078]
Test Loss: 0.633788036497125
Epoch 13 loss = 0.618267917920693
----------
Test err: [0.39544236 0.28954424 0.39142091 0.32171582]
Test Loss: 0.631203970325057
Epoch 14 loss = 0.6237328466397508
----------
Test err: [0.42895442 0.29490617 0.36863271 0.31769437]
Test Loss: 0.6415644996167827
Epoch 15 loss = 0.6086376887863507
----------
Test err: [0.42627346 0.29088472 0.36193029 0.30965147]
Test Loss: 0.624446974922441
Epoch 16 loss = 0.6020179101672952
----------
Test err: [0.42627346 0.23458445 0.33780161 0.31233244]
Test Loss: 0.6001117522690954
Epoch 17 loss = 0.6036912319487605
----------
Test err: [0.43163539 0.35522788 0.42091153 0.29624665]
Test Loss: 0.6629415813823488
Epoch 18 loss = 0.6121956896206648
----------
Test err: [0.36863271 0.25737265 0.34986595 0.31367292]
Test Loss: 0.5978842234943093
Epoch 19 loss = 0.5967928497145707
----------
Test err: [0.36461126 0.33914209 0.38337802 0.29088472]
Test Loss: 0.6333730461789999
Epoch 20 loss = 0.6049996790233949
----------
Test err: [0.36997319 0.32171582 0.39678284 0.31367292]
Test Loss: 0.6338741316013138
Epoch 21 loss = 0.5938402479839069
----------
Test err: [0.39008043 0.29356568 0.33914209 0.28686327]
Test Loss: 0.6223459007298379
Epoch 22 loss = 0.591079430509828
----------
Test err: [0.36193029 0.27613941 0.33780161 0.31099196]
Test Loss: 0.6044045295017015
Epoch 23 loss = 0.6034674793082332
----------
Test err: [0.40616622 0.33512064 0.41957105 0.33512064]
Test Loss: 0.6815995971295213
Epoch 24 loss = 0.6124235767142063
----------
Test err: [0.44906166 0.36595174 0.46648794 0.36327078]
Test Loss: 0.9390195347069096
Epoch 25 loss = 0.5966530990344909
----------
Test err: [0.40080429 0.28150134 0.37935657 0.40348525]
Test Loss: 0.6319409565495742
Epoch 26 loss = 0.5963475651459783
----------
Test err: [0.37935657 0.41018767 0.43431635 0.3150134 ]
Test Loss: 0.7677958436939496
Epoch 27 loss = 0.5882094790085391
----------
Test err: [0.39812332 0.31635389 0.46380697 0.3002681 ]
Test Loss: 0.7249485544920288
Epoch 28 loss = 0.5877567067862196
----------
Test err: [0.38739946 0.30831099 0.42493298 0.40616622]
Test Loss: 0.6600796708552511
Epoch 29 loss = 0.5996335898263845
----------
Test err: [0.4463807  0.37935657 0.40616622 0.39812332]
Test Loss: 2.105508810756906
Epoch 30 loss = 0.5816744695400106
----------
Test err: [0.36863271 0.29624665 0.34450402 0.31099196]
Test Loss: 0.6328663002479892
Epoch 31 loss = 0.5906760949871176
----------
Test err: [0.41018767 0.37801609 0.45710456 0.29758713]
Test Loss: 0.8362394225915979
Epoch 32 loss = 0.5858116314494258
----------
Test err: [0.38873995 0.27747989 0.32707775 0.30294906]
Test Loss: 0.6132919135485994
Epoch 33 loss = 0.5900561978925649
----------
Test err: [0.36461126 0.27882038 0.31769437 0.27747989]
Test Loss: 0.5948352153505381
Epoch 34 loss = 0.5923277596685905
----------
Test err: [0.32975871 0.25335121 0.41018767 0.28552279]
Test Loss: 0.6075498327692775
Epoch 35 loss = 0.5767773217234471
----------
Test err: [0.35924933 0.30160858 0.43699732 0.36058981]
Test Loss: 0.6825961718890047
Epoch 36 loss = 0.5885472332824011
----------
Test err: [0.36729223 0.27613941 0.43297587 0.32037534]
Test Loss: 0.6239449875803799
Epoch 37 loss = 0.5944677885352126
----------
Test err: [0.35924933 0.32975871 0.36997319 0.30697051]
Test Loss: 0.6261360736828467
Epoch 38 loss = 0.58015462907965
----------
Test err: [0.40482574 0.29892761 0.44101877 0.31367292]
Test Loss: 0.6595888055721173
Epoch 39 loss = 0.5979624162091007
----------
Test err: [0.39544236 0.24664879 0.36863271 0.30697051]
Test Loss: 0.6245770023251827
Epoch 40 loss = 0.5978986417959586
----------
Test err: [0.42359249 0.33646113 0.39812332 0.3150134 ]
Test Loss: 0.6708382626960488
Epoch 41 loss = 0.5851550055892474
----------
Test err: [0.39544236 0.23324397 0.34852547 0.30563003]
Test Loss: 0.6080239356143385
Epoch 42 loss = 0.5880273540601654
----------
Test err: [0.36729223 0.2386059  0.33646113 0.28150134]
Test Loss: 0.5975432675781263
Epoch 43 loss = 0.5877063681868382
----------
Test err: [0.35522788 0.27211796 0.3310992  0.28820375]
Test Loss: 0.6072323735673529
Epoch 44 loss = 0.5920889441513184
----------
Test err: [0.35120643 0.28820375 0.43699732 0.33646113]
Test Loss: 0.6416636039340624
Epoch 45 loss = 0.5858750359302551
----------
Test err: [0.35120643 0.26809651 0.38337802 0.28150134]
Test Loss: 0.5975945165265981
Epoch 46 loss = 0.5783041584587608
----------
Test err: [0.37265416 0.24396783 0.37801609 0.34182306]
Test Loss: 0.6155233965442584
Epoch 47 loss = 0.5964123165639412
----------
Test err: [0.40616622 0.41689008 0.45040214 0.2922252 ]
Test Loss: 0.9314993429060117
Epoch 48 loss = 0.5872015249952873
----------
Test err: [0.34316354 0.24798928 0.3458445  0.28552279]
Test Loss: 0.58389821685551
Epoch 49 loss = 0.5905381391578961
----------
Test err: [0.3847185  0.23592493 0.30697051 0.29490617]
Test Loss: 0.5935761674179948
Epoch 50 loss = 0.5828188357340427
